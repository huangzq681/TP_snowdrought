{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract SWE and SST data for Tibetan Plateau and NINO3 region respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_source = ['ACCESS-CM2', 'ACCESS-ESM1-5', 'BCC-CSM2-MR', 'CESM2', 'CESM2-WACCM', 'CIESM', 'CNRM-CM6-1', 'CanESM5', 'CanESM5-1', 'E3SM-1-0', 'E3SM-2-0',\n",
    "'EC-Earth3','EC-Earth3-AerChem','EC-Earth3-CC','EC-Earth3-Veg','GFDL-CM4','GFDL-ESM4','GISS-E2-1-G','GISS-E2-1-H','GISS-E2-2-G','HadGEM3-GC31-LL','IPSL-CM5A2-INCA',\n",
    "'IPSL-CM6A-LR','KIOST-ESM','MIROC6','MPI-ESM-1-2-HAM','MPI-ESM1-2-HR','MPI-ESM1-2-LR','MRI-ESM2-0','NorESM2-LM','NorESM2-MM','TaiESM1']\n",
    "SSP245_source = ['ACCESS-CM2', 'ACCESS-ESM1-5', 'BCC-CSM2-MR', 'CESM2', 'CESM2-WACCM', 'CIESM', 'CNRM-CM6-1', 'CanESM5', 'CanESM5-1',\n",
    "'EC-Earth3','EC-Earth3-CC','EC-Earth3-Veg','GFDL-CM4','GFDL-ESM4','GISS-E2-1-G','GISS-E2-1-H','GISS-E2-2-G','HadGEM3-GC31-LL',\n",
    "'IPSL-CM6A-LR','KIOST-ESM','MIROC6','MPI-ESM1-2-HR','MPI-ESM1-2-LR','MRI-ESM2-0','NorESM2-LM','NorESM2-MM','TaiESM1']\n",
    "SSP370_source = ['E3SM-1-0', 'E3SM-2-0', 'EC-Earth3-AerChem','IPSL-CM5A2-INCA','MPI-ESM-1-2-HAM']\n",
    "NAT_source = ['ACCESS-CM2', 'ACCESS-ESM1-5', 'BCC-CSM2-MR', 'CESM2', 'CNRM-CM6-1', 'CanESM5', 'E3SM-2-0',\n",
    "'GFDL-CM4','GFDL-ESM4','GISS-E2-1-G','HadGEM3-GC31-LL', 'IPSL-CM6A-LR','MIROC6', 'MRI-ESM2-0','NorESM2-LM']\n",
    "\n",
    "hist_variant = {\n",
    "    'ACCESS-CM2':'r1i1p1f1', 'ACCESS-ESM1-5':'r1i1p1f1', 'BCC-CSM2-MR':'r1i1p1f1', 'CESM2':'r10i1p1f1', 'CESM2-WACCM':'r1i1p1f1', 'CIESM':'r1i1p1f1', \n",
    "    'CNRM-CM6-1':'r1i1p1f2', 'CanESM5':'r1i1p1f1', 'CanESM5-1':'r1i1p1f1', 'E3SM-1-0':'r10i2p2f1', 'E3SM-2-0':'r1i1p1f1','EC-Earth3':'r1i1p1f1',\n",
    "    'EC-Earth3-AerChem':'r1i1p1f1','EC-Earth3-CC':'r1i1p1f1','EC-Earth3-Veg':'r1i1p1f1','GFDL-CM4':'r1i1p1f1','GFDL-ESM4':'r1i1p1f1',\n",
    "    'GISS-E2-1-G':'r101i1p1f1','GISS-E2-1-H':'r1i1p1f2','GISS-E2-2-G':'r1i1p3f1','HadGEM3-GC31-LL':'r1i1p1f3','IPSL-CM5A2-INCA':'r1i1p1f1',\n",
    "    'IPSL-CM6A-LR':'r1i1p1f1','KIOST-ESM':'r1i1p1f1','MIROC6':'r1i1p1f1','MPI-ESM-1-2-HAM':'r1i1p1f1','MPI-ESM1-2-HR':'r1i1p1f1','MPI-ESM1-2-LR':'r1i1p1f1',\n",
    "    'MRI-ESM2-0':'r1i1p1f1','NorESM2-LM':'r1i1p1f1','NorESM2-MM':'r1i1p1f1','TaiESM1':'r1i1p1f1'\n",
    "}\n",
    "SSP245_variant = {\n",
    "    'ACCESS-CM2':'r1i1p1f1', 'ACCESS-ESM1-5':'r1i1p1f1', 'BCC-CSM2-MR':'r1i1p1f1', 'CESM2':'r10i1p1f1', 'CESM2-WACCM':'r1i1p1f1', 'CIESM':'r1i1p1f1', \n",
    "    'CNRM-CM6-1':'r1i1p1f2', 'CanESM5':'r1i1p1f1', 'CanESM5-1':'r1i1p1f1', 'EC-Earth3':'r1i1p1f1',\n",
    "    'EC-Earth3-CC':'r1i1p1f1','EC-Earth3-Veg':'r1i1p1f1','GFDL-CM4':'r1i1p1f1','GFDL-ESM4':'r1i1p1f1',\n",
    "    'GISS-E2-1-G':'r101i1p1f1','GISS-E2-1-H':'r1i1p1f2','GISS-E2-2-G':'r1i1p3f1','HadGEM3-GC31-LL':'r1i1p1f3',\n",
    "    'IPSL-CM6A-LR':'r1i1p1f1','KIOST-ESM':'r1i1p1f1','MIROC6':'r1i1p1f1','MPI-ESM1-2-HR':'r1i1p1f1','MPI-ESM1-2-LR':'r1i1p1f1',\n",
    "    'MRI-ESM2-0':'r1i1p1f1','NorESM2-LM':'r1i1p1f1','NorESM2-MM':'r1i1p1f1','TaiESM1':'r1i1p1f1'\n",
    "}\n",
    "SSP370_variant = {\n",
    "    'E3SM-1-0':'r10i2p2f1', 'E3SM-2-0':'r1i1p1f1', 'EC-Earth3-AerChem':'r1i1p1f1','IPSL-CM5A2-INCA':'r1i1p1f1','MPI-ESM-1-2-HAM':'r1i1p1f1'\n",
    "}\n",
    "NAT_variant = {\n",
    "    'ACCESS-CM2':'r1i1p1f1', 'ACCESS-ESM1-5':'r1i1p1f1', 'BCC-CSM2-MR':'r1i1p1f1', 'CESM2':'r1i1p1f1', 'CNRM-CM6-1':'r1i1p1f2', 'CanESM5':'r1i1p1f1',\n",
    "    'E3SM-2-0':'r1i1p1f1','GFDL-CM4':'r1i1p1f1','GFDL-ESM4':'r1i1p1f1','GISS-E2-1-G':'r1i1p1f3','HadGEM3-GC31-LL':'r1i1p1f3', \n",
    "    'IPSL-CM6A-LR':'r1i1p1f1','MIROC6':'r1i1p1f1','MRI-ESM2-0':'r1i1p1f1','NorESM2-LM':'r1i1p1f1'\n",
    "}\n",
    "\n",
    "paths = {\n",
    "    'hist':'/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/historical/regrid',\n",
    "    'SSP245':'/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/ssp245/regrid',\n",
    "    'SSP370':'/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/ssp370/regrid',\n",
    "    'NAT':'/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/NAT/regrid'\n",
    "}\n",
    "\n",
    "paths_2 = {\n",
    "    'hist':'/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/historical',\n",
    "    'SSP245':'/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/ssp245',\n",
    "    'SSP370':'/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/ssp370',\n",
    "    'NAT':'/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/NAT'\n",
    "}\n",
    "\n",
    "TP_range = {'lon1':66, 'lon2':108, 'lat1':22, 'lat2':46}\n",
    "Nino3_region_range = {'lon1':210, 'lon2':270, 'lat1':-5, 'lat2':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select SWE data of the TP region for historical \n",
    "for s in hist_source:\n",
    "    snw_path_s = glob(paths['hist'] + '/' + 'snw' + '*' + s + '_*' + hist_variant[s] + '*.nc')[0]\n",
    "    snw_s = xr.open_dataset(snw_path_s).sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))\n",
    "    if s in SSP245_source:\n",
    "        snw_path_s = glob(paths['SSP245'] + '/' + 'snw' + '*' + s + '_*' + SSP245_variant[s] + '*.nc')[0]\n",
    "        snw_s = xr.concat([snw_s, xr.open_dataset(snw_path_s).sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))], dim='time')\n",
    "    elif s in SSP370_source:\n",
    "        snw_path_s = glob(paths['SSP370'] + '/' + 'snw' + '*' + s + '_*' + SSP370_variant[s] + '*.nc')[0]\n",
    "        snw_s = xr.concat([snw_s, xr.open_dataset(snw_path_s).sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))], dim='time')\n",
    "    # select from 1950~2025\n",
    "    snw_s = snw_s.sel(time=slice('1950', '2025'))\n",
    "    # save to file\n",
    "    snw_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/HIST/' + 'snw' + '_TP_' + s + '_' + hist_variant[s] + '_1950-2025.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeqinhuang/miniforge3/envs/threeDMap/lib/python3.11/site-packages/xarray/conventions.py:551: SerializationWarning: variable 'pr' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n"
     ]
    }
   ],
   "source": [
    "# select pr data of the TP region for historical \n",
    "for s in hist_source:\n",
    "    if s == 'GFDL-CM4':\n",
    "        continue\n",
    "    pr_path_s = glob(paths_2['hist'] + '/' + 'pr' + '*' + s + '_*' + hist_variant[s] + '*.nc')[0]\n",
    "    pr_s = xr.open_dataset(pr_path_s)['pr'].sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))\n",
    "    if s in SSP245_source:\n",
    "        pr_path_s = glob(paths_2['SSP245'] + '/' + 'pr' + '*' + s + '_*' + SSP245_variant[s] + '*.nc')[0]\n",
    "        pr_s = xr.concat([pr_s, xr.open_dataset(pr_path_s)['pr'].sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))], dim='time')\n",
    "    elif s in SSP370_source:\n",
    "        pr_path_s = glob(paths_2['SSP370'] + '/' + 'pr' + '*' + s + '_*' + SSP370_variant[s] + '*.nc')[0]\n",
    "        pr_s = xr.concat([pr_s, xr.open_dataset(pr_path_s)['pr'].sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))], dim='time')\n",
    "    # select from 1950~2025\n",
    "    pr_s = pr_s.sel(time=slice('1950', '2025'))\n",
    "    # save to file\n",
    "    pr_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/HIST/' + 'pr' + '_TP_' + s + '_' + hist_variant[s] + '_1950-2025.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeqinhuang/miniforge3/envs/threeDMap/lib/python3.11/site-packages/xarray/conventions.py:551: SerializationWarning: variable 'tas' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n"
     ]
    }
   ],
   "source": [
    "# select tas data of the TP region for historical \n",
    "for s in hist_source:\n",
    "    if s == 'GFDL-CM4':\n",
    "        continue\n",
    "    tas_path_s = glob(paths_2['hist'] + '/' + 'tas' + '*' + s + '_*' + hist_variant[s] + '*.nc')[0]\n",
    "    tas_s = xr.open_dataset(tas_path_s)['tas'].sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))\n",
    "    if s in SSP245_source:\n",
    "        tas_path_s = glob(paths_2['SSP245'] + '/' + 'tas' + '*' + s + '_*' + SSP245_variant[s] + '*.nc')[0]\n",
    "        tas_s = xr.concat([tas_s, xr.open_dataset(tas_path_s)['tas'].sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))], dim='time')\n",
    "    elif s in SSP370_source:\n",
    "        tas_path_s = glob(paths_2['SSP370'] + '/' + 'tas' + '*' + s + '_*' + SSP370_variant[s] + '*.nc')[0]\n",
    "        tas_s = xr.concat([tas_s, xr.open_dataset(tas_path_s)['tas'].sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))], dim='time')\n",
    "    # select from 1950~2025\n",
    "    tas_s = tas_s.sel(time=slice('1950', '2025'))\n",
    "    # save to file\n",
    "    tas_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/HIST/' + 'tas' + '_TP_' + s + '_' + hist_variant[s] + '_1950-2025.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select SWE data of the TP region for historical \n",
    "for s in ['NorESM2-LM']:\n",
    "    snw_path_s = glob(paths['hist'] + '/' + 'snw' + '*' + s + '_*' + hist_variant[s] + '*.nc')[0]\n",
    "    snw_s = xr.open_dataset(snw_path_s).sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))\n",
    "    if s in SSP245_source:\n",
    "        snw_path_s = glob(paths['SSP245'] + '/' + 'snw' + '*' + s + '_*' + SSP245_variant[s] + '*.nc')[0]\n",
    "        snw_s = xr.concat([snw_s, xr.open_dataset(snw_path_s).sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))], dim='time')\n",
    "    elif s in SSP370_source:\n",
    "        snw_path_s = glob(paths['SSP370'] + '/' + 'snw' + '*' + s + '_*' + SSP370_variant[s] + '*.nc')[0]\n",
    "        snw_s = xr.concat([snw_s, xr.open_dataset(snw_path_s).sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))], dim='time')\n",
    "    # select from 1950~2025\n",
    "    snw_s = snw_s.sel(time=slice('1950', '2025'))\n",
    "    # save to file\n",
    "    snw_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/HIST/' + 'snw' + '_TP_' + s + '_' + hist_variant[s] + '_1950-2025.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select SWE data of the TP region for NAT scenario\n",
    "for s in NAT_source:\n",
    "    snw_path_s = glob(paths['NAT'] + '/' + 'snw' + '*' + s + '_*' + NAT_variant[s] + '*.nc')[0]\n",
    "    snw_s = xr.open_dataset(snw_path_s).sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))\n",
    "    last_year = snw_s['time'][-1].dt.year.values\n",
    "    # select from 1950~last_year\n",
    "    snw_s = snw_s.sel(time=slice('1950', str(last_year)))\n",
    "    # save to file\n",
    "    snw_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/NAT/' + 'snw' + '_TP_' + s + '_' + NAT_variant[s] + '_1950-' + str(last_year) + '.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select pr data of the TP region for NAT scenario\n",
    "for s in NAT_source:\n",
    "    pr_path_s = glob(paths_2['NAT'] + '/' + 'pr' + '*' + s + '_*' + NAT_variant[s] + '*.nc')[0]\n",
    "    pr_s = xr.open_dataset(pr_path_s)['pr'].sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))\n",
    "    last_year = pr_s['time'][-1].dt.year.values\n",
    "    # select from 1950~last_year\n",
    "    pr_s = pr_s.sel(time=slice('1950', str(last_year)))\n",
    "    # save to file\n",
    "    pr_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/NAT/' + 'pr' + '_TP_' + s + '_' + NAT_variant[s] + '_1950-' + str(last_year) + '.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select tas data of the TP region for NAT scenario\n",
    "for s in NAT_source:\n",
    "    tas_path_s = glob(paths_2['NAT'] + '/' + 'tas' + '*' + s + '_*' + NAT_variant[s] + '*.nc')[0]\n",
    "    tas_s = xr.open_dataset(tas_path_s)['tas'].sel(lon=slice(TP_range['lon1'], TP_range['lon2']), lat=slice(TP_range['lat1'], TP_range['lat2']))\n",
    "    last_year = tas_s['time'][-1].dt.year.values\n",
    "    # select from 1950~last_year\n",
    "    tas_s = tas_s.sel(time=slice('1950', str(last_year)))\n",
    "    # save to file\n",
    "    tas_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/NAT/' + 'tas' + '_TP_' + s + '_' + NAT_variant[s] + '_1950-' + str(last_year) + '.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select tos data of the Nino3 region for historical\n",
    "for s in hist_source:\n",
    "    tos_path_s = glob(paths['hist'] + '/' + 'tos' + '*' + s + '_*' + hist_variant[s] + '*.nc')[0]\n",
    "    tos_s = xr.open_dataset(tos_path_s).sel(lon=slice(Nino3_region_range['lon1'], Nino3_region_range['lon2']), lat=slice(Nino3_region_range['lat1'], Nino3_region_range['lat2']))\n",
    "    if s in SSP245_source:\n",
    "        tos_path_s = glob(paths['SSP245'] + '/' + 'tos' + '*' + s + '_*' + SSP245_variant[s] + '*.nc')[0]\n",
    "        tos_s = xr.concat([tos_s, xr.open_dataset(tos_path_s).sel(lon=slice(Nino3_region_range['lon1'], Nino3_region_range['lon2']), lat=slice(Nino3_region_range['lat1'], Nino3_region_range['lat2']))], dim='time')\n",
    "    elif s in SSP370_source:\n",
    "        tos_path_s = glob(paths['SSP370'] + '/' + 'tos' + '*' + s + '_*' + SSP370_variant[s] + '*.nc')[0]\n",
    "        tos_s = xr.concat([tos_s, xr.open_dataset(tos_path_s).sel(lon=slice(Nino3_region_range['lon1'], Nino3_region_range['lon2']), lat=slice(Nino3_region_range['lat1'], Nino3_region_range['lat2']))], dim='time')\n",
    "    # select from 1950~2025\n",
    "    tos_s = tos_s.sel(time=slice('1950', '2025'))\n",
    "    # save to file\n",
    "    tos_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/HIST/' + 'tos' + '_Nino3_' + s + '_' + hist_variant[s] + '_1950-2025.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select tos data of the Nino3 region for NAT scenario\n",
    "for s in NAT_source:\n",
    "    tos_path_s = glob(paths['NAT'] + '/' + 'tos' + '*' + s + '_*' + NAT_variant[s] + '*.nc')[0]\n",
    "    tos_s = xr.open_dataset(tos_path_s).sel(lon=slice(Nino3_region_range['lon1'], Nino3_region_range['lon2']), lat=slice(Nino3_region_range['lat1'], Nino3_region_range['lat2']))\n",
    "    last_year = tos_s['time'][-1].dt.year.values\n",
    "    # select from 1950~last_year\n",
    "    tos_s = tos_s.sel(time=slice('1950', str(last_year)))\n",
    "    # save to file\n",
    "    tos_s.to_netcdf('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/NAT/' + 'tos' + '_Nino3_' + s + '_' + NAT_variant[s] + '_1950-' + str(last_year) + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nino X index computation\n",
    "https://climatedataguide.ucar.edu/climate-data/nino-sst-indices-nino-12-3-34-4-oni-and-tni\n",
    "\n",
    "Nino X Index computation: (a) Compute area averaged total SST from Niño X region; (b) Compute monthly climatology (e.g., 1950-1979) for area averaged total SST from Niño X region, and subtract climatology from area averaged total SST time series to obtain anomalies; (c) Smooth the anomalies with a 5-month running mean; (d) Normalize the smoothed values by its standard deviation over the climatological period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate nino3 index\n",
    "# Nino X Index computation: (a) Compute area averaged total SST from Niño X region; (b) Compute monthly climatology (e.g., 1950-1979) for \n",
    "# area averaged total SST from Niño X region, and subtract climatology from area averaged total SST time series to obtain anomalies; \n",
    "# (c) Smooth the anomalies with a 5-month running mean; (d) Normalize the smoothed values by its standard deviation over the climatological period. \n",
    "def detrend(x, axis=0):\n",
    "    # remove the long-term trend\n",
    "    x = x - np.polyval(np.polyfit(np.arange(len(x)), x, 1), np.arange(len(x)))\n",
    "    return x\n",
    "\n",
    "def nino3_index(tos):\n",
    "    # compute area averaged total SST from Niño X region\n",
    "    tos_nino3 = tos.mean(dim=['lon', 'lat'])\n",
    "    # compute monthly climatology (e.g., 1950-1979) for area averaged total SST from Niño X region\n",
    "    tos_nino3_clim = tos_nino3.sel(time=slice('1950', '1979')).groupby('time.month').mean(dim='time')\n",
    "    # subtract climatology from area averaged total SST time series to obtain anomalies\n",
    "    tos_nino3_anom = tos_nino3.groupby('time.month') - tos_nino3_clim\n",
    "    # remove the long-term trend\n",
    "    tos_nino3_anom = xr.apply_ufunc(detrend, tos_nino3_anom, kwargs={'axis': 0}).where(~tos_nino3_anom.isnull())\n",
    "    # smooth the anomalies with a 5-month running mean\n",
    "    tos_nino3_anom_smooth = tos_nino3_anom.rolling(time=5, center=True).mean()\n",
    "    # normalize the smoothed values by its standard deviation over the climatological period\n",
    "    tos_nino3_anom_smooth_std = tos_nino3_anom_smooth.sel(time=slice('1950', '1979')).std(dim='time')\n",
    "    tos_nino3_index = tos_nino3_anom_smooth / tos_nino3_anom_smooth_std\n",
    "    return tos_nino3_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate nino3 index of each model for historical\n",
    "tos_nino3_index_all = pd.DataFrame()\n",
    "for s in hist_source:\n",
    "    tos = xr.open_dataset('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/HIST/' + 'tos' + '_Nino3_' + s + '_' + hist_variant[s] + '_1950-2025.nc')\n",
    "    tos_nino3_index = nino3_index(tos['tos'])\n",
    "    tos_nino3_index_all[s] = tos_nino3_index\n",
    "\n",
    "tos_nino3_index_all.index = pd.date_range('1950-01', '2026-01', freq='M')\n",
    "tos_nino3_index_all.to_csv('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/HIST/' + 'tos' + '_Nino3_index_1950-2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate nino3 index of each model for NAT\n",
    "tos_nino3_index_all = pd.DataFrame()\n",
    "for s in NAT_source:\n",
    "    tos = xr.open_dataset(glob('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/NAT/' + 'tos' + '_Nino3_' + s + '_' + NAT_variant[s] + '_1950-*.nc')[0])\n",
    "    last_year = tos['time'][-1].dt.year.values\n",
    "    tos_nino3_index = nino3_index(tos['tos'])\n",
    "    tos_nino3_index = tos_nino3_index.to_dataframe()\n",
    "    if s == 'GISS-E2-1-G':\n",
    "        tos_nino3_index.index = pd.date_range('1951-01', str(last_year+1)+'-01', freq='M')\n",
    "    else:\n",
    "        tos_nino3_index.index = pd.date_range('1950-01', str(last_year+1)+'-01', freq='M')\n",
    "    tos_nino3_index_all[s] = tos_nino3_index['tos']\n",
    "\n",
    "tos_nino3_index_all.to_csv('/Volumes/Seagate_ZQ2/SWE_datasets/rawData/CMIP6/NAT/' + 'tos' + '_Nino3_index_1950-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "threeDMap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
